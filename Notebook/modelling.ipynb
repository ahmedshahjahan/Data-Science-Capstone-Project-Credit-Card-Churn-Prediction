{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(dflog[['Height','Weight']].values, \n",
    "                                              (dflog.Gender == \"Male\").values,random_state=5)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# Fit the model on the trainng data.\n",
    "clf.fit(Xlr, ylr)\n",
    "# Print the accuracy from the testing data.\n",
    "print(accuracy_score(clf.predict(Xtestlr), ytestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, Xlr, ylr)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "# your turn\n",
    "best_param_C=0  # Initializing parameter C \n",
    "best_score = 0 # Initializing Score\n",
    "for c in Cs:\n",
    "    logreg = LogisticRegression(C=c)\n",
    "    score = cv_score(logreg, Xlr, ylr)\n",
    "    if score > best_score:\n",
    "        best_param_C = c\n",
    "        best_score = score\n",
    "    print(f'When C = {c}, the score is : {score}')\n",
    "print('C:', best_param_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your turn\n",
    "logit = LogisticRegression(C=best_param_C)\n",
    "logit.fit(Xlr, ylr)\n",
    "y_pred = logit.predict(Xtestlr)\n",
    "accuracy = accuracy_score(ytestlr, y_pred, normalize=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your turn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "logreg_cv.fit(Xlr, ylr)\n",
    "y_pred = logreg_cv.predict(Xtestlr)\n",
    "print('Best parameter:', logreg_cv.best_params_)\n",
    "print('Best score:', logreg_cv.best_score_)\n",
    "print('Test Accuracy:', accuracy_score(ytestlr, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
